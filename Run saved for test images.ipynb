{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./facerecognition_first_modelvgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the load_img() function to load the image and resize it to the required size of 224Ã—224 pixels.\n",
    "dad = load_img('./Data/Test/2/34.jpg', target_size=(224,224))\n",
    "mom = load_img('./Data/Test/1/34.jpg', target_size=(224,224))\n",
    "shashank = load_img('./Data/Test/0/106.jpg', target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we can convert the pixels to a NumPy array so that we can work with it in Keras. \n",
    "# We can use the img_to_array() function for this.\n",
    "dad = img_to_array(dad)\n",
    "mom = img_to_array(mom)\n",
    "shashank = img_to_array(shashank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only have one sample (one image). We can reshape the array by calling reshape() and adding the extra dimension.\n",
    "# img.shape = (224,224,3)\n",
    "dad = dad.reshape(1, dad.shape[0], dad.shape[1], dad.shape[2])\n",
    "mom = mom.reshape(1, mom.shape[0], mom.shape[1], mom.shape[2])\n",
    "shashank = shashank.reshape(1, shashank.shape[0], shashank.shape[1], shashank.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to the model network\n",
    "dad = preprocess_input(dad)\n",
    "mom = preprocess_input(mom)\n",
    "shashank = preprocess_input(shashank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the image and store results in yhat/yh\n",
    "yhdad = model.predict(dad)\n",
    "yhmom = model.predict(mom)\n",
    "yhshashank = model.predict(shashank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9237436  0.07625639 0.        ]] [[5.3248938e-17 1.0000000e+00 0.0000000e+00]] [[1.0000000e+00 2.6807856e-24 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(yhdad, yhmom, yhshashank)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
